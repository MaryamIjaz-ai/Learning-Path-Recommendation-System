{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "AtfQ830PbuVB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPqANwKuVZqy",
        "outputId": "04fe6895-649a-443c-aa9d-50016e166f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted to: extracted_files\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your zip file\n",
        "zip_path = \"/content/archive.zip\"\n",
        "\n",
        "# Directory to extract to\n",
        "extract_dir = \"extracted_files\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"✅ Extracted to: {extract_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn LibRecommender surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6kxnpujWQyL",
        "outputId": "b9c9200f-02dc-4c76-bd77-da3645c828e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: LibRecommender in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from LibRecommender) (4.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from LibRecommender) (4.67.1)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.0.0->LibRecommender) (7.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.0.0->LibRecommender) (1.17.2)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2469530 sha256=896eb56eaedc4dd0df8997ea072f4c5e1185bb2b078b051fbbc7bd17ef6a76c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from libreco.data import DatasetPure, random_split\n",
        "from libreco.algorithms import NCF\n",
        "\n",
        "# Load your course dataset\n",
        "courses = pd.read_csv(\"/content/extracted_files/coursea_data.csv\")\n",
        "\n",
        "# Clean and encode course titles as item IDs\n",
        "courses['item'] = courses.index.astype(int)  # unique numeric ID for each course\n"
      ],
      "metadata": {
        "id": "q2OG3I2VXxDE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simulated Intern-Course Ratings **"
      ],
      "metadata": {
        "id": "rB8n1JXnX-yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n_users = 50\n",
        "n_items = len(courses)\n",
        "ratings = []\n",
        "\n",
        "for user in range(1, n_users + 1):\n",
        "    selected = np.random.choice(courses['item'], 10, replace=False)\n",
        "    for item in selected:\n",
        "        ratings.append([user, item, np.random.randint(3, 6)])  # Ratings: 3 to 5\n",
        "\n",
        "ratings_df = pd.DataFrame(ratings, columns=['user', 'item', 'rating'])\n"
      ],
      "metadata": {
        "id": "q9xLoE3Oa4xH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the SVD Model**"
      ],
      "metadata": {
        "id": "YNHMyfD6YFp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings_df[['user', 'item', 'rating']], reader)\n",
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "svd_model = SVD()\n",
        "svd_model.fit(trainset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pn2rJHObbuq",
        "outputId": "bd55e739-a178-4833-92d4-6f42def3d4b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ad4576298d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Content-Based Filtering (TF-IDF on Metadata)**"
      ],
      "metadata": {
        "id": "719K5GSXcqJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine metadata into single content field\n",
        "courses['content'] = (\n",
        "    courses['course_title'].astype(str) + ' ' +\n",
        "    courses['course_organization'].astype(str) + ' ' +\n",
        "    courses['course_Certificate_type'].astype(str) + ' ' +\n",
        "    courses['course_difficulty'].astype(str)\n",
        ")\n",
        "\n",
        "# TF-IDF + Cosine Similarity\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(courses['content'])\n",
        "content_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Map item ID to index\n",
        "item_to_index = {item: idx for idx, item in enumerate(courses['item'])}\n"
      ],
      "metadata": {
        "id": "najegN8kcvmw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Recommendation Function**"
      ],
      "metadata": {
        "id": "k9zZGhCscyVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommend(user_id, top_n=5, alpha=0.7):\n",
        "    rated_items = ratings_df[ratings_df['user'] == user_id]['item'].tolist()\n",
        "    all_items = courses['item'].tolist()\n",
        "    candidates = [i for i in all_items if i not in rated_items]\n",
        "\n",
        "    recommendations = []\n",
        "\n",
        "    for item in candidates:\n",
        "        # Collaborative score from SVD\n",
        "        collab_score = svd_model.predict(user_id, item).est\n",
        "\n",
        "        # Content score: average similarity to rated items\n",
        "        sim_scores = []\n",
        "        for rated in rated_items:\n",
        "            if item in item_to_index and rated in item_to_index:\n",
        "                sim_scores.append(content_sim[item_to_index[item]][item_to_index[rated]])\n",
        "        content_score = np.mean(sim_scores) if sim_scores else 0\n",
        "\n",
        "        # Hybrid score\n",
        "        final_score = alpha * collab_score + (1 - alpha) * content_score\n",
        "        recommendations.append((item, final_score))\n",
        "\n",
        "    # Top-N Recommendations\n",
        "    top_recs = sorted(recommendations, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "    print(f\"\\n🎓 Top {top_n} Recommended Courses for Intern {user_id}:\\n\")\n",
        "    for item_id, score in top_recs:\n",
        "        row = courses[courses['item'] == item_id].iloc[0]\n",
        "        print(f\"- {row['course_title']} ({row['course_organization']}) | Difficulty: {row['course_difficulty']} | Score: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "wJU9m4Zrc2Hb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the Recommender**"
      ],
      "metadata": {
        "id": "0lpkZ9GedHIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_recommend(user_id=10, top_n=5, alpha=0.7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dze_Bn66dJCb",
        "outputId": "37f381f7-9c79-4826-f8b7-783cd54fb3a8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎓 Top 5 Recommended Courses for Intern 10:\n",
            "\n",
            "- Introduction to Business Analytics: Communicating with Data (University of Illinois at Urbana-Champaign) | Difficulty: Intermediate | Score: 2.99\n",
            "- Methods and Statistics in Social Sciences (University of Amsterdam) | Difficulty: Beginner | Score: 2.98\n",
            "- The Science of Gastronomy (The Hong Kong University of Science and Technology) | Difficulty: Mixed | Score: 2.97\n",
            "- High Performance Collaboration: Leadership, Teamwork, and Negotiation (Northwestern University) | Difficulty: Mixed | Score: 2.97\n",
            "- Anatomy (University of Michigan) | Difficulty: Beginner | Score: 2.97\n"
          ]
        }
      ]
    }
  ]
}